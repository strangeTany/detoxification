{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.seq2seq import Seq2SeqModel, Seq2SeqArgs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.981983</td>\n",
       "      <td>0.014195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.999039</td>\n",
       "      <td>0.065473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>Well, we could spare your life, for one.</td>\n",
       "      <td>0.919051</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.985068</td>\n",
       "      <td>0.213313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.994215</td>\n",
       "      <td>0.053362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.999348</td>\n",
       "      <td>0.009402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0           0   \n",
       "1             1           1   \n",
       "2             2           2   \n",
       "3             3           3   \n",
       "4             4           4   \n",
       "\n",
       "                                           reference  \\\n",
       "0  if Alkar floods her with her mental waste, it ...   \n",
       "1                        you're becoming disgusting.   \n",
       "2                      well, we can spare your life.   \n",
       "3                       monkey, you have to wake up.   \n",
       "4                         I have orders to kill her.   \n",
       "\n",
       "                                         translation  similarity  lenght_diff  \\\n",
       "0  If Alkar is flooding her with psychic waste, t...    0.785171     0.010309   \n",
       "1                          Now you're getting nasty.    0.749687     0.071429   \n",
       "2           Well, we could spare your life, for one.    0.919051     0.268293   \n",
       "3          Ah! Monkey, you've got to snap out of it.    0.664333     0.309524   \n",
       "4                   I've got orders to put her down.    0.726639     0.181818   \n",
       "\n",
       "    ref_tox   trn_tox  \n",
       "0  0.981983  0.014195  \n",
       "1  0.999039  0.065473  \n",
       "2  0.985068  0.213313  \n",
       "3  0.994215  0.053362  \n",
       "4  0.999348  0.009402  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('preprocessed.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(frac=0.8, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>You're arrogant. You have the sickness that el...</td>\n",
       "      <td>you are overwhelmed by the disease that elites...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>why? Because some stupid college counselor tol...</td>\n",
       "      <td>Why, because some jaded college counselor said...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>the bitch, she thought bitterly, probably turn...</td>\n",
       "      <td>The sloven, she thought bitterly, has probably...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>I dabble in my chest and back a week, a month ...</td>\n",
       "      <td>Then I wax chest and back weekly, sack and cra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>I should have taken that crummy cashier's job.</td>\n",
       "      <td>I should have taken that lousy job as a cashier.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_text  \\\n",
       "85  You're arrogant. You have the sickness that el...   \n",
       "65  why? Because some stupid college counselor tol...   \n",
       "90  the bitch, she thought bitterly, probably turn...   \n",
       "49  I dabble in my chest and back a week, a month ...   \n",
       "86     I should have taken that crummy cashier's job.   \n",
       "\n",
       "                                          target_text  \n",
       "85  you are overwhelmed by the disease that elites...  \n",
       "65  Why, because some jaded college counselor said...  \n",
       "90  The sloven, she thought bitterly, has probably...  \n",
       "49  Then I wax chest and back weekly, sack and cra...  \n",
       "86   I should have taken that lousy job as a cashier.  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={\"reference\": \"input_text\", \"translation\": \"target_text\"})\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train = pd.DataFrame(train, columns = ['input_text','target_text'])\n",
    "test = pd.DataFrame(test, columns = ['input_text','target_text'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>I can't believe Okwe never fucked you.</td>\n",
       "      <td>I can't believe Okwe never drove you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>I don't need a mountain for chumps.</td>\n",
       "      <td>I don't need a bunny hill.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Damn, I'm glad you're back in town. Yeah, me too.</td>\n",
       "      <td>I'm damn glad you're back in town.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>he's ashamed of you because you have a blob in...</td>\n",
       "      <td>He's ashamed of you, because your copybook is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>We're gonna send you a rape whistle. Huh?</td>\n",
       "      <td>we're gonna send you an anti-rape whistle, okay?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_text  \\\n",
       "93             I can't believe Okwe never fucked you.   \n",
       "57                I don't need a mountain for chumps.   \n",
       "91  Damn, I'm glad you're back in town. Yeah, me too.   \n",
       "39  he's ashamed of you because you have a blob in...   \n",
       "88          We're gonna send you a rape whistle. Huh?   \n",
       "\n",
       "                                          target_text  \n",
       "93              I can't believe Okwe never drove you.  \n",
       "57                         I don't need a bunny hill.  \n",
       "91                 I'm damn glad you're back in town.  \n",
       "39  He's ashamed of you, because your copybook is ...  \n",
       "88   we're gonna send you an anti-rape whistle, okay?  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = Seq2SeqArgs()\n",
    "model_args.eval_batch_size = 64\n",
    "model_args.evaluate_generated_text = True\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.evaluate_during_training_steps = 2500\n",
    "model_args.evaluate_during_training_verbose = True\n",
    "model_args.fp16 = False\n",
    "model_args.learning_rate = 5e-5\n",
    "model_args.max_seq_length = 128\n",
    "model_args.num_train_epochs = 2\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.save_eval_checkpoints = False\n",
    "model_args.save_steps = -1\n",
    "model_args.train_batch_size = 8\n",
    "model_args.use_multiprocessing = False\n",
    "\n",
    "model_args.do_sample = True\n",
    "model_args.num_beams = 1\n",
    "model_args.num_return_sequences = 1\n",
    "model_args.max_length = 128\n",
    "model_args.top_k = 50\n",
    "model_args.top_p = 0.95\n",
    "model_args.output_dir = \"./models\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44a13b4d5f44c61a47c0de8a934615b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b3fb79657a496ba721c3554533cc5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26eae10caba04089b57acfd3e3e8e367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfe475e12414d35a9b9ffd16c7a2585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada56a4042ba4c99b69f40e3a7981b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/strangetany/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "/Users/strangetany/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:437: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " {'global_step': [10],\n",
       "  'eval_loss': [8.733986854553223],\n",
       "  'train_loss': [9.102274894714355]})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Seq2SeqModel(\n",
    "    encoder_decoder_type=\"bart\",\n",
    "    encoder_decoder_name=\"facebook/bart-large\",\n",
    "    args=model_args,\n",
    "    use_cuda=False,\n",
    "    use_mps_device = True\n",
    ")\n",
    "model.train_model(train, eval_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753b9a6c423a4e94a8e4663970803716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/strangetany/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "/Users/strangetany/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:437: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test[\"input_text\"][:5].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I want to believe Okwe never fucked you.',\n",
       " \"Why didn't the mountain provide a pass for sledging.\",\n",
       " \"Loyalty to anybody: I'm Glad you're back in town, Mr. Clinton. Yeah, me too.\",\n",
       " \"He's ashamed of you because you have a blob in your life.\",\n",
       " 'If I had a rape whistle, would you call me a feminist, what should I do?']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93               I can't believe Okwe never fucked you.\n",
       "57                  I don't need a mountain for chumps.\n",
       "91    Damn, I'm glad you're back in town. Yeah, me too.\n",
       "39    he's ashamed of you because you have a blob in...\n",
       "88            We're gonna send you a rape whistle. Huh?\n",
       "Name: input_text, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"input_text\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
